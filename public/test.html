<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Face Expression Recognition</title>
    <script src="face-api.min.js"></script>
    <style>
      body {
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        margin: 0;
        background: #222;
      }
      video,
      canvas {
        position: absolute;
      }
    </style>
  </head>
  <body>
    <video id="video" width="720" height="560" autoplay muted></video>
    <canvas id="overlay" width="720" height="560"></canvas>
    <script>
      let predictedAges = []
      function interpolateAgePredictions(age) {
        predictedAges = [age].concat(predictedAges).slice(0, 30)
        const avgPredictedAge =
          predictedAges.reduce((total, a) => total + a) / predictedAges.length
        return avgPredictedAge
      }

      // Load the models and start the video stream
      async function start() {
        await faceapi.nets.tinyFaceDetector.loadFromUri('./models')
        await faceapi.nets.faceExpressionNet.loadFromUri('./models')
        await faceapi.nets.faceLandmark68Net.loadFromUri('./models')
        await faceapi.nets.ssdMobilenetv1.loadFromUri('./models')
        await faceapi.nets.ageGenderNet.loadFromUri('./models')

        const video = document.getElementById('video')
        navigator.mediaDevices.getUserMedia({ video: {} }).then((stream) => {
          video.srcObject = stream
        })

        video.addEventListener('play', onPlay)

        async function onPlay() {
          const videoEl = document.getElementById('video')

          if (videoEl.paused || videoEl.ended) return setTimeout(onPlay)

          const result = await faceapi
            .detectSingleFace(videoEl)
            .withFaceExpressions()
            .withAgeAndGender()

          if (result) {
            const canvas = document.getElementById('overlay')
            const dims = faceapi.matchDimensions(canvas, videoEl, true)

            const resizedResult = faceapi.resizeResults(result, dims)
            const minConfidence = 0.05
            faceapi.draw.drawDetections(canvas, resizedResult)
            faceapi.draw.drawFaceExpressions(
              canvas,
              resizedResult,
              minConfidence
            )

            const { age, gender, genderProbability } = result
            const interpolatedAge = interpolateAgePredictions(age)

            // Collect all results into a single array
            const resultsText = [
              `Age: ${faceapi.utils.round(interpolatedAge, 0)} years`,
              `Gender: ${gender} (${faceapi.utils.round(
                genderProbability * 100,
                2
              )}%)`,
            ]

            // Adjust the position to draw all results in one block without overlapping the face expressions
            const textPosition = result.detection.box.bottomRight
            textPosition.y += 20 // Adjust this value as needed to avoid overlap

            // Draw all results in one block at the new position
            new faceapi.draw.DrawTextField(resultsText, textPosition).draw(
              canvas
            )
          }
          setTimeout(onPlay)
        }
      }

      start()
    </script>
  </body>
</html>
